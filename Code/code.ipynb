{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9deb168e",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788797fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0d2a7",
   "metadata": {},
   "source": [
    "### csv 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "submission = pd.read_csv(\"./submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ddcd7",
   "metadata": {},
   "source": [
    "### train에서 선형보간 없애고 새로운 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_linear_interps(df, y='nins', id_col='pv_id', t_col='time',\n",
    "                        min_run=2, rtol=1e-7, atol=1e-9,\n",
    "                        slope_eps=1e-8, level_eps=1e-6):\n",
    "    df = df.sort_values([id_col, t_col]).reset_index(drop=True).copy()\n",
    "    df[y] = pd.to_numeric(df[y], errors='coerce').astype('float64')\n",
    "\n",
    "    g = df.groupby(id_col, sort=False)\n",
    "    d_prev = g[y].diff()\n",
    "    d_next = g[y].transform(lambda s: s.shift(-1) - s)\n",
    "\n",
    "    diff1 = (d_next - d_prev).abs()\n",
    "    scale = np.maximum(d_prev.abs(), d_next.abs())\n",
    "    tol = atol + rtol * scale.fillna(0)\n",
    "    lin_inside = np.isfinite(d_prev) & np.isfinite(d_next) & (diff1 <= tol)\n",
    "\n",
    "    flat_zero = (df[y].abs() <= level_eps) & (d_prev.abs() <= slope_eps)\n",
    "\n",
    "    df['_lin_inside'] = lin_inside.values\n",
    "    df['_slope_step'] = d_prev.values\n",
    "    df['_block']      = g['_lin_inside'].transform(lambda s: s.ne(s.shift()).cumsum())\n",
    "    df['_run_len']    = df.groupby([id_col, '_block'])['_lin_inside'].transform('size')\n",
    "\n",
    "    df['is_interp_like'] = df['_lin_inside'] & (df['_run_len'] >= min_run) & (~flat_zero)\n",
    "\n",
    "    seg = (df[df['is_interp_like']]\n",
    "           .groupby([id_col, '_block'], as_index=False)\n",
    "           .agg(start_time=(t_col, 'first'),\n",
    "                end_time=(t_col, 'last'),\n",
    "                points=('is_interp_like', 'size'),\n",
    "                slope_per_step=('_slope_step', 'median'))\n",
    "           .sort_values([id_col, 'start_time']))\n",
    "    return df, seg\n",
    "\n",
    "tagged, segments = flag_linear_interps(\n",
    "    train, y='nins', id_col='pv_id', t_col='time',\n",
    "    min_run=10, rtol=1e-7, atol=1e-9,\n",
    "    slope_eps=1e-8, level_eps=1e-6\n",
    ")\n",
    "\n",
    "cols = [c for c in [\n",
    "    'pv_id',\n",
    "    'left_anchor_time','missing_start_time','missing_end_time','right_anchor_time',\n",
    "    'start_time','end_time',\n",
    "    'points','duration_min','slope_per_step'\n",
    "] if c in segments.columns]\n",
    "\n",
    "print(\"총 보간 의심 구간 수:\", len(segments))\n",
    "print(\"고유 발전소 수:\", segments['pv_id'].nunique())\n",
    "\n",
    "train_nan = tagged.copy()\n",
    "train_nan.loc[train_nan['is_interp_like'], 'nins'] = np.nan\n",
    "\n",
    "helper_cols = ['_lin_inside','_slope_step','_block','_run_len','_row',\n",
    "               'is_interp_like','pv_num','_d2']\n",
    "train_nan.drop(columns=[c for c in helper_cols if c in train_nan.columns], inplace=True)\n",
    "\n",
    "train_nan = train_nan.sort_values(['pv_id','time']).reset_index(drop=True)\n",
    "train_nan.to_csv('train_clean_ver2.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"원본 행수: {len(train):,}\")\n",
    "print(f\"NaN 처리 포함 행수(동일): {len(train_nan):,}\")\n",
    "print(\"저장 완료: train_clean_ver2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfaf48",
   "metadata": {},
   "source": [
    "### 추론 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train_clean_ver2.csv\")\n",
    "\n",
    "BLACKLIST = {f'PV_ID_{i}' for i in [49,39,28]}\n",
    "\n",
    "def weighted_average_by_time(\n",
    "    train: pd.DataFrame,\n",
    "    target_pv: str = 'PV_ID_40',\n",
    "    power: float = 2.0,\n",
    "    eps: float = 1e-6,\n",
    "    topk = 55,\n",
    "    return_real=True,\n",
    "    visualize=True\n",
    "):\n",
    "    target = test[test['pv_id'] == target_pv].copy()\n",
    "\n",
    "    source = train.copy()\n",
    "    target_times = target['time'].unique()\n",
    "    source_f = source[source['time'].isin(target_times)].copy()\n",
    "    source_f = source_f[~source_f['pv_id'].isin(BLACKLIST)]\n",
    "\n",
    "    target_idx = target.index.to_numpy()\n",
    "    preds = np.empty(len(target), dtype=float)\n",
    "\n",
    "    src_g = source_f.groupby('time')\n",
    "    tgt_g = target.groupby('time')\n",
    "\n",
    "    common_times = np.intersect1d(source_f['time'].unique(), target['time'].unique())\n",
    "\n",
    "    if len(common_times) >= 2:\n",
    "        ct_sorted = np.sort(pd.to_datetime(common_times))\n",
    "        step_sec = int((ct_sorted[1] - ct_sorted[0]).total_seconds())\n",
    "    else:\n",
    "        step_sec = 300\n",
    "\n",
    "    for t in tqdm(common_times):\n",
    "        src = src_g.get_group(t)\n",
    "        tgt = tgt_g.get_group(t)\n",
    "\n",
    "        S    = src[['coord1','coord2']].to_numpy(dtype=float)\n",
    "        y    = src['nins'].to_numpy(dtype=float)\n",
    "        S_pv = src['pv_id'].to_numpy()\n",
    "\n",
    "        T = tgt[['coord1','coord2']].to_numpy(dtype=float)\n",
    "\n",
    "        diff = T[:, None, :] - S[None, :, :]\n",
    "        D = np.linalg.norm(diff, axis=2)\n",
    "\n",
    "        if (topk is None) or (isinstance(topk, (int, float)) and topk <= 0):\n",
    "            k = S.shape[0]\n",
    "            idx_topk = np.tile(np.arange(S.shape[0]), (T.shape[0], 1))\n",
    "        else:\n",
    "            k = min(int(topk), S.shape[0])\n",
    "            idx_topk = np.argpartition(D, kth=k-1, axis=1)[:, :k]\n",
    "\n",
    "        Dk = np.take_along_axis(D, idx_topk, axis=1)\n",
    "        yk = y[idx_topk]\n",
    "        W  = 1.0 / (np.power(Dk, power) + eps)\n",
    "\n",
    "        mask = ~np.isnan(yk)\n",
    "\n",
    "        Wm  = np.where(mask, W, 0.0)\n",
    "        ykm = np.where(mask, yk, 0.0)\n",
    "        num = (Wm * ykm).sum(axis=1)\n",
    "        den = Wm.sum(axis=1) + 1e-12\n",
    "        pred_t = num / den\n",
    "\n",
    "        preds[np.searchsorted(target_idx, tgt.index.to_numpy())] = pred_t\n",
    "\n",
    "    if return_real:\n",
    "        reals = target['nins'].to_numpy(dtype=float)\n",
    "        return preds, reals\n",
    "    else:\n",
    "        return preds, common_times\n",
    "\n",
    "def pick_closest_test_pv(current_train: pd.DataFrame, test_df: pd.DataFrame, candidates: list[str]) -> str:\n",
    "    tr_coords = current_train.groupby('pv_id')[['coord1','coord2']].first().dropna()\n",
    "    te_coords = test_df.groupby('pv_id')[['coord1','coord2']].first().dropna()\n",
    "\n",
    "    tr_arr = tr_coords.to_numpy(dtype=float)\n",
    "    best_pv, best_d = None, np.inf\n",
    "    for pv in candidates:\n",
    "        if pv not in te_coords.index:\n",
    "            continue\n",
    "        tx, ty = te_coords.loc[pv, ['coord1','coord2']].astype(float).to_numpy()\n",
    "        d = np.linalg.norm(tr_arr - np.array([tx, ty], dtype=float), axis=1).min()\n",
    "        if d < best_d:\n",
    "            best_d, best_pv = d, pv\n",
    "    return best_pv\n",
    "\n",
    "current_train = train.copy()\n",
    "remaining = list(test['pv_id'].unique())\n",
    "\n",
    "step = 0\n",
    "while remaining:\n",
    "    step += 1\n",
    "    target_id = pick_closest_test_pv(current_train, test, remaining)\n",
    "\n",
    "    preds, common_times = weighted_average_by_time(\n",
    "        current_train,\n",
    "        target_pv=target_id,\n",
    "        power=2.0,\n",
    "        eps=1e-8,\n",
    "        topk=55,\n",
    "        return_real=False,\n",
    "        visualize=False\n",
    "    )\n",
    "\n",
    "    mask_sub = (submission['pv_id'] == target_id) & (submission['time'].isin(common_times))\n",
    "    submission.loc[mask_sub, 'nins'] = preds\n",
    "\n",
    "    add_df = test[(test['pv_id'] == target_id) & (test['time'].isin(common_times))].copy()\n",
    "    add_df['nins'] = preds\n",
    "    current_train = pd.concat([current_train, add_df], ignore_index=True)\n",
    "\n",
    "    print(f\"[{step}] added {target_id} (|times|={len(common_times)}) → train size: {len(current_train)}\")\n",
    "    remaining.remove(target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_ma3(g):\n",
    "    s = g['nins']\n",
    "    s_ma = s.rolling(window=3, center=True, min_periods=1).mean()\n",
    "    s_fwd = s_ma.rolling(window=3, min_periods=1).mean()\n",
    "    s_bwd = s_fwd[::-1].rolling(window=3, min_periods=1).mean()[::-1]\n",
    "    g['nins_smooth'] = s_bwd\n",
    "    return g\n",
    "\n",
    "df = submission.sort_values(['pv_id','time'])\n",
    "df = df.groupby('pv_id', group_keys=False).apply(two_sided_ma3)\n",
    "\n",
    "submission['nins'] = df['nins_smooth']\n",
    "submission.to_csv(\"my_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6cd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
